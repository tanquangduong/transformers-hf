{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfb2b7d-dfd5-4f13-b4ec-dd501fb88c08",
   "metadata": {},
   "source": [
    "## Example 1 - ðŸ¤— 'transformers' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b6ccc0-30f0-44f6-af53-634e0450dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\easyb\\Anaconda3\\envs\\transformer\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\easyb\\Anaconda3\\envs\\transformer\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\easyb\\Anaconda3\\envs\\transformer\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\easyb\\Anaconda3\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.772534966468811}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries from Hugging Face's transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the model name. In this case, we're using a pre-trained BERT model for multilingual sentiment analysis\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# Load the pre-trained tokenizer associated with the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create a pipeline for sentiment analysis. This pipeline will use the specified model and tokenizer\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Use the classifier to analyze the sentiment of a text string\n",
    "classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81de5d-0ae3-4fa8-a4b8-40c1ef82299d",
   "metadata": {},
   "source": [
    "## Example 2 - ðŸ¤— 'datasets' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c336309-99ff-492d-a7be-98bb5c772b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n",
      "\n",
      "\n",
      "{'text': 'i didnt feel humiliated', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "# Import the load_dataset function from the datasets library\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define the name of the dataset we want to load. In this case, it's the \"emotion\" dataset\n",
    "dataset_name = \"emotion\"\n",
    "# Use the load_dataset function to load the specified dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# Print the loaded dataset\n",
    "print(dataset)\n",
    "print(\"\\n\")\n",
    "# Print the first sample from the 'train' split of the dataset\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758ef38",
   "metadata": {},
   "source": [
    "## Example 3: Using the Transformers Library for Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d1a928-81fe-4de9-bf50-4780c3a453c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 7592, 19081, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Define the model name. \n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# Load the pre-trained tokenizer associated with the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define a text string\n",
    "text = \"Hello transformers!\"\n",
    "\n",
    "# Tokenize the text string\n",
    "tokens = tokenizer(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a66f8aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 19081, 999, 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a17fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
